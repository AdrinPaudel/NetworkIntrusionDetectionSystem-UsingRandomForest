================================================================================
                      MODULE 5: MODEL TESTING
                       DETAILED STEP-BY-STEP LOG
                  Generated: 2026-01-25 21:26:45
================================================================================

This log provides a detailed chronological record of every testing
operation performed, including prediction generation, metrics calculation,
and comprehensive evaluation analysis.

================================================================================

STEP 1: LOAD TRAINED MODEL AND TEST DATA
================================================================================

Purpose: Load trained model and held-out test data for evaluation

[SUBSTEP 1.1] Load Trained Model
  • File: trained_model/random_forest_model.joblib
  • Format: Joblib (compressed pickle)
  • Action: joblib.load('random_forest_model.joblib')
  • Model type: RandomForestClassifier
  • Model parameters:
      n_estimators: 100
      max_depth: 30
      min_samples_split: 5
      min_samples_leaf: 1
      max_features: 'sqrt'
  • Model size: ~1.8 GB in memory
  • Status: ✓ MODEL LOADED

[SUBSTEP 1.2] Load Preprocessing Objects
  • Scaler: data/preprocessed/scaler.joblib
    - Type: StandardScaler
    - Purpose: Feature scaling metadata
  • Label Encoder: data/preprocessed/label_encoder.joblib
    - Classes: 7 attack types
    - Mapping: 0=Benign, 1=Botnet, 2=Brute Force, 3=DDoS, 4=DoS, 5=Infiltration, 6=Web Attack
  • Status: ✓ OBJECTS LOADED

[SUBSTEP 1.3] Load Test Data
  • File: data/preprocessed/test_final.parquet
  • Format: Apache Parquet (columnar storage)
  • Action: pd.read_parquet('test_final.parquet')
  • Test samples: 2,395,881
  • Features: 45 (same as training)
  • Target: Label (encoded 0-6)
  • Memory: ~314 MB
  • Status: ✓ TEST DATA LOADED

[SUBSTEP 1.4] Separate Features and Target
  • Features (X_test): All columns except 'Label'
  • Target (y_test): 'Label' column
  • Shape verification: X_test=(2,395,881, 45), y_test=(2,395,881,)
  • Data types: All numeric (float32/int32)
  • Status: ✓ VERIFIED

[SUBSTEP 1.5] Analyze Test Set Class Distribution
  • Purpose: Understand test set composition (original, no SMOTE)
  • Distribution:
      0: Benign       - 2,125,608 (88.72%)
      1: Botnet       -    28,907 ( 1.21%)
      2: Brute Force  -    18,820 ( 0.79%)
      3: DDoS         -   155,191 ( 6.48%)
      4: DoS          -    39,314 ( 1.64%)
      5: Infiltration -    27,868 ( 1.16%)
      6: Web Attack   -       173 ( 0.01%)
  • Total: 2,395,881 samples
  • Imbalance: Benign dominant (88.72%), Web Attack rare (0.01%)
  • Status: Natural distribution preserved ✓

STEP 2: GENERATE PREDICTIONS
================================================================================

Purpose: Generate class predictions and probability scores on test set

[SUBSTEP 2.1] Predict Class Labels
  • Method: model.predict(X_test)
  • Input: 2,395,881 samples × 45 features
  • Output: 2,395,881 predicted class labels (0-6)
  • Action: y_pred = model.predict(X_test)
  • Duration: 4.35 seconds
  • Throughput: 551,022 samples/second
  • Latency: 0.0018 ms per sample
  • Status: ✓ PREDICTIONS GENERATED

[SUBSTEP 2.2] Predict Class Probabilities
  • Method: model.predict_proba(X_test)
  • Input: 2,395,881 samples × 45 features
  • Output: 2,395,881 × 7 probability matrix
  • Action: y_pred_proba = model.predict_proba(X_test)
  • Duration: 4.4 seconds
  • Throughput: 544,518 samples/second
  • Status: ✓ PROBABILITIES GENERATED

[SUBSTEP 2.3] Analyze Prediction Confidence
  • Metric: Maximum probability per sample
  • Method: max(P(class_i)) for each sample
  • Statistics:
      Mean confidence: 0.9838 (98.38%)
      Median confidence: 0.9999 (99.99%)
      Std deviation: 0.0824
      Min confidence: 0.2667
      Max confidence: 1.0000
      Q25 (25th percentile): 0.9900
      Q75 (75th percentile): 1.0000
  • High confidence samples (>0.95): 2,357,751 (98.41%)
  • Medium confidence (0.50-0.95): 36,773 (1.54%)
  • Low confidence (<0.50): 1,357 (0.06%)
  • Insight: Model very confident in most predictions

[SUBSTEP 2.4] Identify Low Confidence Predictions
  • Threshold: <0.50 probability
  • Count: 1,357 samples (0.06% of test set)
  • These may be:
      - Borderline cases (ambiguous features)
      - Misclassified samples
      - Edge cases (rare attack variants)
  • Recommended: Manual review for production deployment
  • Status: Low confidence rate acceptable ✓

STEP 3: MULTICLASS EVALUATION (7-Class Classification)
================================================================================

Purpose: Evaluate performance across all 7 attack classes

[SUBSTEP 3.1] Generate Confusion Matrix
  • Method: confusion_matrix(y_test, y_pred)
  • Shape: 7×7 matrix (rows=true, cols=predicted)
  • Total samples: 2,395,881
  • Diagonal sum (correct): 2,365,598 (98.74%)
  • Off-diagonal sum (errors): 30,283 (1.26%)
  • Status: ✓ MATRIX GENERATED

[SUBSTEP 3.2] Calculate Per-Class Metrics
  • Method: precision_recall_fscore_support()
  • Metrics calculated for each class:
      - Precision: TP / (TP + FP)
      - Recall: TP / (TP + FN)
      - F1-Score: 2 × (Precision × Recall) / (Precision + Recall)
      - Support: Number of true samples

  Per-Class Results:
    Class 0 (Benign):
      Precision: 0.9885, Recall: 0.9975, F1: 0.9930, Support: 2,125,608
    Class 1 (Botnet):
      Precision: 1.0000, Recall: 0.9960, F1: 0.9980, Support: 28,907
    Class 2 (Brute Force):
      Precision: 0.9996, Recall: 0.9995, F1: 0.9995, Support: 18,820
    Class 3 (DDoS):
      Precision: 0.9984, Recall: 0.9985, F1: 0.9984, Support: 155,191
    Class 4 (DoS):
      Precision: 0.9998, Recall: 0.9998, F1: 0.9998, Support: 39,314
    Class 5 (Infiltration):
      Precision: 0.4584, Recall: 0.1207, F1: 0.1911, Support: 27,868
    Class 6 (Web Attack):
      Precision: 0.1067, Recall: 0.9538, F1: 0.1919, Support: 173

  • Status: ✓ PER-CLASS METRICS CALCULATED

[SUBSTEP 3.3] Calculate Aggregate Metrics
  • Overall Accuracy: 0.9874 (98.74%)
  • Macro Average:
      Precision: 0.7930 (79.30%)
      Recall: 0.8665 (86.65%)
      F1-Score: 0.7674 (76.74%)
  • Weighted Average:
      Precision: 0.9866 (98.66%)
      Recall: 0.9874 (98.74%)
      F1-Score: 0.9842 (98.42%)
  • Observation: Large gap between macro (76.74%) and weighted (98.42%)
  • Reason: Poor performance on rare classes (Infiltration, Web Attack)
  • Status: ✓ AGGREGATE METRICS CALCULATED

[SUBSTEP 3.4] Generate Classification Report
  • Method: classification_report()
  • Format: Text table with per-class metrics
  • Decimal places: 4 (high precision)
  • Includes: Precision, Recall, F1, Support for all 7 classes
  • Includes: Macro, weighted averages
  • Status: ✓ REPORT GENERATED

[SUBSTEP 3.5] Calculate ROC Curves and AUC
  • Method: One-vs-Rest (OvR) approach
  • Process: Binarize labels, calculate ROC for each class
  • Per-Class AUC:
      Benign: 0.9882
      Botnet: 1.0000
      Brute Force: 1.0000
      DDoS: 1.0000
      DoS: 1.0000
      Infiltration: 0.9050
      Web Attack: 0.9997
  • Macro Average AUC: 0.9847 (98.47%)
  • Observation: Excellent AUC for most classes
  • Observation: Infiltration AUC (0.905) lower but still good
  • Status: ✓ AUC SCORES CALCULATED

[SUBSTEP 3.6] Visualize Multiclass Results
  • Created: confusion_matrix_multiclass.png
      - 7×7 heatmap with counts and percentages
      - Annotated with row-normalized values
      - Color scale: Blue (low) to Red (high)
  • Created: per_class_metrics_bar.png
      - Bar chart showing Precision, Recall, F1 per class
      - Grouped bars for easy comparison
      - Highlights Infiltration/Web Attack issues
  • Created: roc_curves_multiclass.png
      - 7 ROC curves (one per class)
      - Includes macro/micro averages
      - Shows AUC scores in legend
  • Created: f1_comparison.png
      - Comparison of per-class F1 scores
      - Sorted by performance
      - Highlights best/worst classes
  • Status: ✓ ALL VISUALIZATIONS CREATED

STEP 4: BINARY EVALUATION (Benign vs Attack)
================================================================================

Purpose: Evaluate binary classification performance (attack detection)

[SUBSTEP 4.1] Binarize Labels
  • True labels: 0=Benign, 1-6=Attack
  • Predicted labels: 0=Benign, 1-6=Attack
  • Action: y_test_binary = (y_test != 0).astype(int)
  • Action: y_pred_binary = (y_pred != 0).astype(int)
  • Benign samples: 2,125,608 (88.72%)
  • Attack samples: 270,273 (11.28%)
  • Status: ✓ LABELS BINARIZED

[SUBSTEP 4.2] Calculate Binary Confusion Matrix
  • True Negatives (TN): 2,120,204 (Benign → Benign)
  • False Positives (FP): 5,404 (Benign → Attack)
  • False Negatives (FN): 24,659 (Attack → Benign)
  • True Positives (TP): 245,614 (Attack → Attack)
  • Total correct: 2,365,818 (98.75%)
  • Total errors: 30,063 (1.25%)
  • Status: ✓ BINARY CONFUSION MATRIX CALCULATED

[SUBSTEP 4.3] Calculate Binary Metrics
  • Accuracy: 0.9875 (98.75%)
  • Precision: 0.9785 (97.85%)
      → Of predicted attacks, 97.85% are real attacks
  • Recall (TPR): 0.9088 (90.88%)
      → Of real attacks, 90.88% detected
  • Specificity (TNR): 0.9975 (99.75%)
      → Of benign traffic, 99.75% correctly classified
  • F1-Score: 0.9423 (94.23%)
  • False Positive Rate (FPR): 0.0025 (0.25%)
      → Only 0.25% benign traffic misclassified as attack
  • False Negative Rate (FNR): 0.0912 (9.12%)
      → 9.12% attacks missed (went undetected)
  • Status: ✓ BINARY METRICS CALCULATED

[SUBSTEP 4.4] Calculate Binary ROC and AUC
  • Method: Use probability of attack (1 - P(Benign))
  • ROC curve: TPR vs FPR at various thresholds
  • AUC: 0.9882 (98.82%)
  • Interpretation: Excellent discrimination between benign and attack
  • Status: ✓ BINARY ROC/AUC CALCULATED

[SUBSTEP 4.5] Visualize Binary Results
  • Created: confusion_matrix_binary.png
      - 2×2 heatmap (Benign vs Attack)
      - Annotated with counts and percentages
      - Shows TN, FP, FN, TP
  • Created: roc_curve_binary.png
      - Single ROC curve for binary classification
      - Diagonal reference line (random classifier)
      - AUC displayed in title
  • Status: ✓ BINARY VISUALIZATIONS CREATED

STEP 5: ERROR ANALYSIS
================================================================================

Purpose: Detailed analysis of misclassifications

[SUBSTEP 5.1] Count Total Errors
  • Total misclassifications: 30,283 (1.26% of test set)
  • False Negatives: 24,659 (81.43% of errors)
  • False Positives: 5,404 (17.85% of errors)
  • Other confusion: 220 (0.73% - attack-to-attack errors)
  • Observation: FN >> FP (more attacks missed than false alarms)
  • Status: ✓ ERRORS COUNTED

[SUBSTEP 5.2] Analyze Confusion Pairs
  • Method: Extract all (true_class, pred_class) pairs where true ≠ pred
  • Total unique confusion pairs: 42
  • Top 10 confusion pairs (sorted by frequency):
      1. Infiltration → Benign: 24,500 (80.90% of all errors)
      2. Benign → Infiltration: 3,974 (13.12%)
      3. Benign → Web Attack: 1,180 (3.90%)
      4. Benign → DDoS: 249 (0.82%)
      5. DDoS → Web Attack: 197 (0.65%)
      6. Botnet → Benign: 116 (0.38%)
      7. DDoS → Benign: 34 (0.11%)
      8. Brute Force → DoS: 8 (0.03%)
      9. DoS → Brute Force: 8 (0.03%)
      10. Web Attack → Benign: 6 (0.02%)
  • Dominant error: Infiltration misclassified as Benign
  • Status: ✓ CONFUSION PAIRS ANALYZED

[SUBSTEP 5.3] Analyze False Negatives by Attack Type
  • Purpose: Understand which attacks are missed
  • False Negatives (Attack → Benign):
      Botnet: 116 (0.40% of Botnet samples missed)
      Brute Force: 2 (0.01% missed) - EXCELLENT
      DDoS: 34 (0.02% missed) - EXCELLENT
      DoS: 1 (0.003% missed) - EXCELLENT
      Infiltration: 24,500 (87.90% missed) - CRITICAL ISSUE
      Web Attack: 6 (3.47% missed) - ACCEPTABLE
  • Critical finding: 87.9% of Infiltration attacks go undetected
  • Root cause: Infiltration is stealthy, mimics benign traffic
  • Status: ✓ FN ANALYSIS COMPLETED

[SUBSTEP 5.4] Analyze False Positives by Attack Type
  • Purpose: Understand false alarm patterns
  • False Positives (Benign → Attack):
      Benign → DDoS: 249 (0.01% of benign flagged)
      Benign → DoS: 1 (0.0001%)
      Benign → Infiltration: 3,974 (0.19%)
      Benign → Web Attack: 1,180 (0.06%)
  • Total FP rate: 0.25% (very low - good)
  • Most common: Benign misclassified as Infiltration
  • Status: ✓ FP ANALYSIS COMPLETED

[SUBSTEP 5.5] Calculate Per-Class Error Rates
  • Benign: 5,404 errors out of 2,125,608 (0.25% error rate)
  • Botnet: 116 errors out of 28,907 (0.40%)
  • Brute Force: 10 errors out of 18,820 (0.05%)
  • DDoS: 429 errors out of 155,191 (0.28%)
  • DoS: 9 errors out of 39,314 (0.02%)
  • Infiltration: 24,506 errors out of 27,868 (87.93%) - CRITICAL
  • Web Attack: 8 errors out of 173 (4.62%)
  • Status: ✓ ERROR RATES CALCULATED

STEP 6: PERFORMANCE ASSESSMENT
================================================================================

Purpose: Assess model performance against targets and production readiness

[SUBSTEP 6.1] Compare Against Target Metrics
  • Target: Macro F1-Score >0.96
    Actual: 0.7674 (76.74%)
    Status: ✗ NOT MET (shortfall of 19.26%)
  • Target: Overall Accuracy >0.99
    Actual: 0.9874 (98.74%)
    Status: ✗ NOT MET (shortfall of 0.26%)
  • Target: Infiltration F1 >0.89
    Actual: 0.1911 (19.11%)
    Status: ✗ NOT MET (shortfall of 69.89%)
  • Conclusion: Model does not meet all targets

[SUBSTEP 6.2] Assess Strengths
  • ✓ Excellent at common attacks (DDoS, DoS, Brute Force): >99.8% F1
  • ✓ High overall accuracy: 98.74%
  • ✓ Low false positive rate: 0.25%
  • ✓ Fast inference: 551K samples/second
  • ✓ High confidence: 98.4% samples >95% confidence
  • ✓ Excellent AUC scores: 98.47% macro average

[SUBSTEP 6.3] Assess Weaknesses
  • ✗ Poor Infiltration detection: 87.9% missed (F1=0.191)
  • ✗ Poor Web Attack precision: 10.7% (many false alarms)
  • ✗ Macro F1 below target: 76.74% vs 96% target
  • ✗ High FN rate for sophisticated attacks
  • ⚠ Relies heavily on SMOTE for minority classes

[SUBSTEP 6.4] Root Cause Analysis
  • Infiltration issue:
      - Stealthy attacks designed to blend with normal traffic
      - Limited training samples (after 80/20 split)
      - Feature overlap with benign traffic
      - May require specialized detection (anomaly detection)
  • Web Attack issue:
      - Extremely rare: Only 173 samples in test set
      - High recall (95.4%) but low precision (10.7%)
      - Model overpredicts this class (false alarms)
      - Limited diversity in training data

[SUBSTEP 6.5] Production Readiness Assessment
  • Use case 1: Binary attack detection (Benign vs Attack)
      Status: ✓ PRODUCTION READY
      Justification: 94.2% F1, 0.25% FPR, 90.9% recall
  • Use case 2: Common attack detection (DDoS, DoS, Botnet, Brute Force)
      Status: ✓ PRODUCTION READY
      Justification: >99.8% F1 for these classes
  • Use case 3: Full 7-class classification
      Status: ⚠ CONDITIONAL
      Justification: Excellent overall, but Infiltration unreliable
  • Use case 4: Infiltration detection
      Status: ✗ NOT READY
      Justification: 87.9% miss rate unacceptable
  • Overall: ✓ PRODUCTION READY (with limitations noted)

STEP 7: GENERATE TESTING REPORT
================================================================================

Purpose: Create comprehensive human-readable testing report

[SUBSTEP 7.1] Compile Report Sections
  • Section 1: Testing Overview
  • Section 2: Inference Performance
  • Section 3: Multiclass Evaluation (7 classes)
  • Section 4: Binary Evaluation (Benign vs Attack)
  • Section 5: Error Analysis
  • Section 6: Conclusion and Recommendations

[SUBSTEP 7.2] Write Report to File
  • File: reports/testing/testing_results.txt
  • Format: Text with ASCII formatting
  • Length: 102 lines
  • Sections: 6 main sections
  • Status: ✓ REPORT CREATED

[SUBSTEP 7.3] Report Quality Checks
  • Check: All metrics included ✓
  • Check: Confusion matrices summarized ✓
  • Check: Per-class results detailed ✓
  • Check: Error analysis comprehensive ✓
  • Check: Production assessment clear ✓
  • Conclusion: Report complete and actionable

================================================================================
                            TESTING SUMMARY
================================================================================

✓ STEP 1: Loaded trained model and test data (2.4M samples)
✓ STEP 2: Generated predictions (551K samples/sec, 98.4% confidence)
✓ STEP 3: Evaluated multiclass performance (Macro F1: 0.767)
✓ STEP 4: Evaluated binary performance (Binary F1: 0.942)
✓ STEP 5: Analyzed errors (30K errors, 81% from Infiltration)
✓ STEP 6: Assessed production readiness (READY with limitations)
✓ STEP 7: Generated testing report and visualizations

TESTING COMPLETED SUCCESSFULLY

Key Results:
  • Overall Accuracy: 98.74%
  • Macro F1-Score: 0.7674 (target: >0.96) ✗
  • Weighted F1-Score: 0.9842
  • Binary F1-Score: 0.9423 ✓
  • Inference Speed: 551,022 samples/second ✓
  • False Positive Rate: 0.25% (excellent) ✓
  • False Negative Rate: 9.12% (acceptable) ⚠

Performance by Class:
  ⭐ EXCELLENT (F1 > 0.99): Benign, Botnet, Brute Force, DDoS, DoS
  ⚠ POOR (F1 < 0.20): Infiltration, Web Attack

Critical Finding:
  • Infiltration: 87.9% miss rate (24,500 undetected attacks)
  • Root cause: Stealthy attacks mimic benign traffic
  • Recommendation: Implement specialized Infiltration detector

Production Recommendation:
  ✓ DEPLOY for binary attack detection (Benign vs Attack)
  ✓ DEPLOY for common attacks (DDoS, DoS, Botnet, Brute Force)
  ⚠ DO NOT RELY on Infiltration detection (manual review required)
  ⚠ Web Attack predictions require human verification (low precision)

Model Strengths:
  • Fast inference (real-time capable)
  • Low false positive rate (0.25%)
  • Excellent at volume-based attacks
  • High overall accuracy (98.74%)
  • Robust and stable predictions

Model Limitations:
  • Cannot detect sophisticated stealthy attacks
  • Limited by feature engineering (flow-based features)
  • Requires additional mechanisms for Infiltration

================================================================================
                          END OF TESTING LOG
================================================================================
